<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AudioContext & WebAssembly Capabilities Test</title>
</head>
<body>
    <h2>AudioContext & WebAssembly Capabilities Test</h2>

    <label for="renderSize">Enter renderSizeHint (integer or "hardware"):</label>
    <input type="text" id="renderSize" value="hardware"><br><br>

    <label for="latencyHint">Enter latencyHint ("interactive", "playback", "balanced" or a number in seconds for exact):</label>
    <input type="text" id="latencyHint" value="interactive"><br><br>

    <label for="sampleRate">Enter desired sampleRate (leave blank for default):</label>
    <input type="text" id="sampleRate" value=""><br><br>

    <button onclick="testRenderSize()">Test AudioContext</button>
    <button onclick="testWasmCapabilities()">Check WebAssembly Capabilities</button>
    <button onclick="listAudioDevices()">List Audio Devices</button>
    <pre id="output"></pre>

    <script>
        async function listAudioDevices() {
            document.getElementById('output').textContent = ''; // Clear logs
            log("Enumerating audio devices...");
            try {
                // Request permission if not already granted, to get device labels
                await navigator.mediaDevices.getUserMedia({ audio: true });
            } catch (e) {
                log("Microphone access denied or not granted. Device labels may be hidden.");
            }
            const devices = await navigator.mediaDevices.enumerateDevices();
            const audioInputs = devices.filter(d => d.kind === "audioinput");
            const audioOutputs = devices.filter(d => d.kind === "audiooutput");

            log(`Audio Input Devices (${audioInputs.length}):`);
            audioInputs.forEach((device, i) => {
                log(`  [${i}] label: "${device.label || '(no label)'}", id: ${device.deviceId}`);
            });

            log(`Audio Output Devices (${audioOutputs.length}):`);
            audioOutputs.forEach((device, i) => {
                log(`  [${i}] label: "${device.label || '(no label)'}", id: ${device.deviceId}`);
            });
        }

        function log(message) {
            const output = document.getElementById('output');
            output.textContent += message + '\n';
        }

        async function testRenderSize() {
            document.getElementById('output').textContent = ''; // Clear previous logs

            const renderHintInput = document.getElementById('renderSize').value;
            const renderSizeHint = isNaN(renderHintInput) ? renderHintInput : parseInt(renderHintInput, 10);

            const latencyHintInput = document.getElementById('latencyHint').value;
            const latencyHint = (!isNaN(latencyHintInput) && latencyHintInput.trim() !== "")
                ? parseFloat(latencyHintInput)
                : latencyHintInput;

            const sampleRateInput = document.getElementById('sampleRate').value;
            const sampleRate = (!isNaN(sampleRateInput) && sampleRateInput.trim() !== "")
                ? parseInt(sampleRateInput, 10)
                : undefined;

            const contextOptions = {
                renderSizeHint,
                latencyHint
            };
            if (sampleRate !== undefined) contextOptions.sampleRate = sampleRate;

            log(`Requesting microphone access...`);
            let stream;
            let audioCtx;
            try {
                stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                log(`Microphone access granted.`);

                try {
                    const track = stream.getAudioTracks()[0];
                    const settings = track.getSettings();
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    const selectedDevice = devices.find(
                        d => d.kind === "audioinput" && d.deviceId === settings.deviceId
                    );
                    if (selectedDevice) {
                        log(`Selected audio input device: "${selectedDevice.label || '(no label)'}" (id: ${selectedDevice.deviceId})`);
                    } else {
                        log(`Selected audio input deviceId: ${settings.deviceId} (label unavailable)`);
                    }
                } catch (e) {
                    log("Could not determine selected audio input device.");
                }

                try {
                    log("Audio output device selection (setSinkId): " + ("setSinkId" in HTMLMediaElement.prototype ? "‚úÖ" : "‚ùå Not supported"));
                } catch (e) {
                    log("Error checking setSinkId support: " + e.message);
                }

                log(`Creating AudioContext with options: ${JSON.stringify(contextOptions)}`);
                try {
                    audioCtx = new AudioContext(contextOptions);
                    log(`AudioContext created successfully.`);
                    log("Maximum output channel count: " + audioCtx.destination.maxChannelCount);
                } catch (error) {
                    log(`Error creating AudioContext: ${error.message}`);
                    stream.getTracks().forEach(track => track.stop());
                    return;
                }

                log(`AudioContext sampleRate: ${audioCtx.sampleRate}`);
                log(`AudioContext baseLatency: ${audioCtx.baseLatency}`);

                const processorCode = `
                    class SizeProcessor extends AudioWorkletProcessor {
                        constructor() {
                            super();
                            this.reported = false;
                        }
                        process(inputs, outputs, parameters) {
                            if (!this.reported) {
                                const bufferSize = outputs[0][0].length;
                                this.port.postMessage({ actualRenderQuantumSize: bufferSize });
                                this.reported = true;
                            }
                            return true;
                        }
                    }
                    registerProcessor('size-processor', SizeProcessor);
                `;

                log(`Adding AudioWorklet module...`);
                try {
                    await audioCtx.audioWorklet.addModule(URL.createObjectURL(new Blob([processorCode], { type: 'application/javascript' })));
                    log(`AudioWorklet module added successfully.`);
                } catch (error) {
                    log(`Error adding AudioWorklet module: ${error.message}`);
                    audioCtx.close();
                    stream.getTracks().forEach(track => track.stop());
                    return;
                }

                log("AudioWorklet support: " + (typeof AudioWorkletNode === "function" ? "‚úÖ" : "‚ùå Not available in this browser"));

                log(`Creating AudioWorkletNode...`);
                const workletNode = new AudioWorkletNode(audioCtx, 'size-processor');

                workletNode.port.onmessage = (event) => {
                    log(`Actual render quantum size reported by processor: ${event.data.actualRenderQuantumSize} frames`);
                    audioCtx.close().then(() => log(`AudioContext closed.`));
                    stream.getTracks().forEach(track => track.stop());
                    log(`Microphone stream stopped.`);
                };

                log(`Connecting microphone stream to AudioWorkletNode...`);
                const source = audioCtx.createMediaStreamSource(stream);
                source.connect(workletNode).connect(audioCtx.destination);

            } catch (error) {
                log(`Microphone access denied: ${error.message}`);
                if (stream) stream.getTracks().forEach(track => track.stop());
                if (audioCtx) audioCtx.close();
            }
        }

        async function testWasiImportSupport() {
            // Minimal WASI module (compiled from: (module (import "wasi_snapshot_preview1" "proc_exit" (func))))
            const wasiModuleBytes = new Uint8Array([
                0x00,0x61,0x73,0x6d,0x01,0x00,0x00,0x00,0x01,0x07,0x01,0x60,0x00,0x00,0x02,0x1a,0x01,0x15,0x77,0x61,0x73,0x69,0x5f,0x73,0x6e,0x61,0x70,0x73,0x68,0x6f,0x74,0x5f,0x70,0x72,0x65,0x76,0x69,0x65,0x77,0x31,0x09,0x70,0x72,0x6f,0x63,0x5f,0x65,0x78,0x69,0x74,0x00,0x00
            ]);
            try {
                const module = new WebAssembly.Module(wasiModuleBytes);
                const imports = WebAssembly.Module.imports(module);
                const hasWasi = imports.some(i => i.module === "wasi_snapshot_preview1");
                return hasWasi;
            } catch (e) {
                return false;
            }
        }

        async function testWasmCapabilities() {
            document.getElementById('output').textContent = ''; // Clear logs
            log("Checking WebAssembly support...");

            const basicSupport = typeof WebAssembly === "object" &&
                                typeof WebAssembly.instantiate === "function";
            log("WebAssembly object and instantiate support: " + (basicSupport ? "‚úÖ" : "‚ùå"));

            if (!basicSupport) return;

            const executionSupport = await testWasmExecution();
            log("WebAssembly binary execution test: " + (executionSupport ? "‚úÖ Successful" : "‚ùå Failed"));

            // These features require special HTTP headers (COOP/COEP) that cannot be set on GitHub Pages.
            // If they appear unsupported, it may be due to server configuration, not your browser.
            const sharedBufferSupport = typeof SharedArrayBuffer === "function";
            log(
                "SharedArrayBuffer support: " +
                (sharedBufferSupport
                    ? "‚úÖ"
                    : "‚ùå Not available (may be due to missing COOP/COEP headers on this server, not browser capability)")
            );

            const atomicsSupport = typeof Atomics === "object" && typeof Atomics.wait === "function";
            const wasmThreadsSupport = sharedBufferSupport && atomicsSupport;
            log(
                "WebAssembly threads support (SharedArrayBuffer + Atomics): " +
                (wasmThreadsSupport
                    ? "‚úÖ"
                    : "‚ùå Not available (may be due to missing COOP/COEP headers on this server, not browser capability)")
            );

            const wasiSupport = typeof WebAssembly === "object" &&
                WebAssembly.Module &&
                WebAssembly.Module.imports;

            if (wasiSupport) {
                const wasiImportSupport = await testWasiImportSupport();
                log("WASI support via import inspection: " + (wasiImportSupport ? "‚úÖ" : "üîç Partial (WebAssembly.Module.imports supported, WASI module not found)"));
            } else {
                log("WASI support: ‚ùå Not available (WebAssembly.Module.imports not supported)");
            }
             
            const simdSupported = WebAssembly.validate(new Uint8Array([
                0x00,0x61,0x73,0x6d,0x01,0x00,0x00,0x00,0x01,0x0a,0x02,0x60,0x00,0x00,0x60,0x00,0x00,
                0x03,0x02,0x01,0x01,0x0a,0x09,0x01,0x07,0x00,0xfd,0x00,0x0b
            ]));
            log("WebAssembly SIMD support: " + (simdSupported ? "‚úÖ" : "‚ùå Not available, or limited"));

            log("WebAssembly BigInt integration: " + (typeof WebAssembly.Global === "function" && typeof BigInt === "function" ? "‚úÖ" : "‚ùå Not available"));

            try {
                const mem = new WebAssembly.Memory({initial:1, maximum:2});
                mem.grow(1);
                log("WebAssembly.Memory grow: ‚úÖ");
            } catch {
                log("WebAssembly.Memory grow: ‚ùå");
            }

            // Run JIT detection after all other checks
            testJitMode();
        }

        function js_square(value) {
            return value * value;
        }

        function go(N) {
            let result = 0;
            // First loop: only numbers
            const start1 = performance.now();
            for (let i = 0; i < N; i++) {
                result = js_square(i % 999);
            }
            const end1 = performance.now();

            // Second loop: mix numbers and objects to trigger deopt
            const start2 = performance.now();
            for (let i = 0; i < N; i++) {
                if ((i % 10000) < 999) {
                    result += js_square(i % 999);
                } else {
                    js_square({ x: 42 });
                }
            }
            const end2 = performance.now();

            return {
                timeNoDeopt: end1 - start1,
                timeDeopt: end2 - start2,
                result
            };
        }

        function isRunningInJitlessMode() {
            // Warm up
            go(1e4);

            const { timeNoDeopt, timeDeopt } = go(1e6);
            const ratio = timeDeopt / timeNoDeopt;
            console.log("JIT deoptimization ratio: " + ratio);
            return ratio <= 12;
        }

        function testJitMode() {
            // Do NOT clear logs; just append the result
            const mode = isRunningInJitlessMode() ? "jitless (interpreter only)" : "jitted (JIT compiler enabled)";
            log("JavaScript engine mode detected: " + mode);
        }

        async function testWasmExecution() {
            try {
                const module = new WebAssembly.Module(
                    new Uint8Array([
                        0x00, 0x61, 0x73, 0x6D, // magic number
                        0x01, 0x00, 0x00, 0x00  // version
                    ])
                );
                new WebAssembly.Instance(module);
                return true;
            } catch {
                return false;
            }
        }
    </script>
</body>
</html>

<!-- This HTML file tests the capabilities of AudioContext and WebAssembly in the browser.
     It includes input fields for renderSizeHint and latencyHint, and buttons to test the AudioContext
     and WebAssembly capabilities. The results are displayed in a preformatted text area. -->
